{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "Aq4_NmwaW2MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataset dari file CSV\n",
        "data = pd.read_csv('tujuan_data.csv')\n",
        "print(data.head(10))"
      ],
      "metadata": {
        "id": "NPDjK8f9b1IH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00245c7-e3ba-4f2d-82d2-d359eddbe700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   teknik_1  teknik_2  teknik_3  teknik_4  teknik_5  teknik_6  teknik_7  \\\n",
            "0         4         5         4         5         3         3         3   \n",
            "1         4         3         4         4         5         3         3   \n",
            "2         4         4         3         4         3         5         5   \n",
            "3         5         4         3         5         5         5         4   \n",
            "4         5         4         3         5         5         4         4   \n",
            "5         3         5         5         5         5         5         5   \n",
            "6         3         3         3         5         5         4         5   \n",
            "7         5         4         3         5         4         4         4   \n",
            "8         5         4         5         3         4         3         3   \n",
            "9         5         5         4         5         4         4         4   \n",
            "\n",
            "   teknik_8  teknik_9  teknik_10  ...  kesehatan_2  kesehatan_3  kesehatan_4  \\\n",
            "0         4         3          5  ...            3            3            1   \n",
            "1         4         4          3  ...            1            2            3   \n",
            "2         3         4          4  ...            4            1            4   \n",
            "3         5         5          5  ...            4            3            2   \n",
            "4         3         3          3  ...            2            3            2   \n",
            "5         4         4          4  ...            1            1            3   \n",
            "6         4         3          5  ...            3            2            1   \n",
            "7         5         4          4  ...            4            4            4   \n",
            "8         3         4          4  ...            2            3            4   \n",
            "9         3         4          5  ...            2            4            3   \n",
            "\n",
            "   kesehatan_5  kesehatan_6  kesehatan_7  kesehatan_8  kesehatan_9  \\\n",
            "0            4            1            3            3            3   \n",
            "1            4            1            3            1            2   \n",
            "2            3            2            3            2            1   \n",
            "3            3            4            4            4            4   \n",
            "4            3            3            1            1            2   \n",
            "5            2            3            1            1            1   \n",
            "6            3            2            1            2            1   \n",
            "7            2            3            2            2            1   \n",
            "8            3            1            1            1            2   \n",
            "9            3            2            1            4            1   \n",
            "\n",
            "   kesehatan_10   minat  \n",
            "0             4  Teknik  \n",
            "1             1  Teknik  \n",
            "2             2  Teknik  \n",
            "3             3  Teknik  \n",
            "4             4  Teknik  \n",
            "5             3  Teknik  \n",
            "6             2  Teknik  \n",
            "7             4  Teknik  \n",
            "8             1  Teknik  \n",
            "9             2  Teknik  \n",
            "\n",
            "[10 rows x 71 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah kolom minat menjadi angka menggunakan LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "data['tipe_encoded'] = label_encoder.fit_transform(data['minat'])\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "_qpRb4cib2Wb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaaa938-80f6-465b-8969-d6b24e23420a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      teknik_1  teknik_2  teknik_3  teknik_4  teknik_5  teknik_6  teknik_7  \\\n",
            "0            4         5         4         5         3         3         3   \n",
            "1            4         3         4         4         5         3         3   \n",
            "2            4         4         3         4         3         5         5   \n",
            "3            5         4         3         5         5         5         4   \n",
            "4            5         4         3         5         5         4         4   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "4995         3         3         1         2         1         1         3   \n",
            "4996         2         2         1         2         1         1         1   \n",
            "4997         3         2         2         3         1         3         1   \n",
            "4998         3         3         2         3         4         4         1   \n",
            "4999         1         2         2         1         1         4         2   \n",
            "\n",
            "      teknik_8  teknik_9  teknik_10  ...  kesehatan_3  kesehatan_4  \\\n",
            "0            4         3          5  ...            3            1   \n",
            "1            4         4          3  ...            2            3   \n",
            "2            3         4          4  ...            1            4   \n",
            "3            5         5          5  ...            3            2   \n",
            "4            3         3          3  ...            3            2   \n",
            "...        ...       ...        ...  ...          ...          ...   \n",
            "4995         3         4          2  ...            5            5   \n",
            "4996         1         4          3  ...            4            4   \n",
            "4997         4         1          1  ...            3            4   \n",
            "4998         2         2          2  ...            5            3   \n",
            "4999         3         2          3  ...            5            3   \n",
            "\n",
            "      kesehatan_5  kesehatan_6  kesehatan_7  kesehatan_8  kesehatan_9  \\\n",
            "0               4            1            3            3            3   \n",
            "1               4            1            3            1            2   \n",
            "2               3            2            3            2            1   \n",
            "3               3            4            4            4            4   \n",
            "4               3            3            1            1            2   \n",
            "...           ...          ...          ...          ...          ...   \n",
            "4995            5            4            3            5            5   \n",
            "4996            3            5            3            3            5   \n",
            "4997            4            4            3            5            3   \n",
            "4998            4            3            3            5            4   \n",
            "4999            5            4            4            3            3   \n",
            "\n",
            "      kesehatan_10      minat  tipe_encoded  \n",
            "0                4     Teknik             6  \n",
            "1                1     Teknik             6  \n",
            "2                2     Teknik             6  \n",
            "3                3     Teknik             6  \n",
            "4                4     Teknik             6  \n",
            "...            ...        ...           ...  \n",
            "4995             4  Kesehatan             1  \n",
            "4996             5  Kesehatan             1  \n",
            "4997             5  Kesehatan             1  \n",
            "4998             4  Kesehatan             1  \n",
            "4999             5  Kesehatan             1  \n",
            "\n",
            "[5000 rows x 72 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan preprocessing pada dataset\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "tipe_encoded = data['tipe_encoded'].values.reshape(-1, 1)\n",
        "tipe_encoded = onehot_encoder.fit_transform(tipe_encoded)\n",
        "tipe_encoded_df = pd.DataFrame(tipe_encoded, columns=['tipe_' + str(i) for i in range(tipe_encoded.shape[1])])\n",
        "data = pd.concat([data, tipe_encoded_df], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBsPhv_fcbq2",
        "outputId": "b8c79902-770a-42a1-abbb-001180e01908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan fitur dan label\n",
        "X = data.drop(['teknik_1', 'teknik_2', 'teknik_3', 'teknik_4', 'teknik_5', 'teknik_6', 'teknik_7', 'teknik_8', 'teknik_9', 'teknik_10', 'sosial_1', 'sosial_2', 'sosial_3', 'sosial_4', 'sosial_5', 'sosial_6', 'sosial_7', 'sosial_8', 'sosial_9', 'sosial_10', 'mipa_1', 'mipa_2', 'mipa_3', 'mipa_4', 'mipa_5', 'mipa_6', 'mipa_7', 'mipa_8', 'mipa_9', 'mipa_10', 'feb_1', 'feb_2', 'feb_3', 'feb_4', 'feb_5', 'feb_6', 'feb_7', 'feb_8', 'feb_9', 'feb_10', 'sastra_1', 'sastra_2', 'sastra_3', 'sastra_4', 'sastra_5', 'sastra_6', 'sastra_7', 'sastra_8', 'sastra_9', 'sastra_10', 'pendidikan_1', 'pendidikan_2', 'pendidikan_3','pendidikan_4', 'pendidikan_5', 'pendidikan_6', 'pendidikan_7', 'pendidikan_8', 'pendidikan_9', 'pendidikan_10', 'kesehatan_1', 'kesehatan_2', 'kesehatan_3', 'kesehatan_4','kesehatan_5', 'kesehatan_6', 'kesehatan_7', 'kesehatan_8', 'kesehatan_9', 'kesehatan_10', 'minat', 'tipe_encoded'], axis=1)\n",
        "y = data['tipe_encoded']"
      ],
      "metadata": {
        "id": "EiPPye33b5Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Tf_jFIF6b6ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "wF93WfU2b9Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Uktj1YSLb_au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1)"
      ],
      "metadata": {
        "id": "aBzw-rs0cAnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e138f4-2199-4955-bb3f-88c0588b74e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "400/400 [==============================] - 2s 2ms/step - loss: -94.5406 - accuracy: 0.1405\n",
            "Epoch 2/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -1730.8708 - accuracy: 0.1405\n",
            "Epoch 3/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -7350.8169 - accuracy: 0.1405\n",
            "Epoch 4/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -18537.7109 - accuracy: 0.1405\n",
            "Epoch 5/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -36493.5898 - accuracy: 0.1405\n",
            "Epoch 6/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -62001.9141 - accuracy: 0.1405\n",
            "Epoch 7/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -95565.2812 - accuracy: 0.1405\n",
            "Epoch 8/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -137597.0625 - accuracy: 0.1405\n",
            "Epoch 9/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -188368.9219 - accuracy: 0.1405\n",
            "Epoch 10/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -248366.2188 - accuracy: 0.1405\n",
            "Epoch 11/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -318339.9062 - accuracy: 0.1405\n",
            "Epoch 12/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -398251.3125 - accuracy: 0.1405\n",
            "Epoch 13/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -488580.2812 - accuracy: 0.1405\n",
            "Epoch 14/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: -589862.5000 - accuracy: 0.1405\n",
            "Epoch 15/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: -702281.3750 - accuracy: 0.1405\n",
            "Epoch 16/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: -825775.3125 - accuracy: 0.1405\n",
            "Epoch 17/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -961500.5625 - accuracy: 0.1405\n",
            "Epoch 18/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -1109770.5000 - accuracy: 0.1405\n",
            "Epoch 19/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -1270795.6250 - accuracy: 0.1405\n",
            "Epoch 20/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -1445155.6250 - accuracy: 0.1405\n",
            "Epoch 21/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -1632905.0000 - accuracy: 0.1405\n",
            "Epoch 22/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -1833925.8750 - accuracy: 0.1405\n",
            "Epoch 23/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -2049011.5000 - accuracy: 0.1405\n",
            "Epoch 24/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -2279324.0000 - accuracy: 0.1405\n",
            "Epoch 25/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -2524926.0000 - accuracy: 0.1405\n",
            "Epoch 26/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -2785976.2500 - accuracy: 0.1405\n",
            "Epoch 27/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -3062880.5000 - accuracy: 0.1405\n",
            "Epoch 28/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -3356304.2500 - accuracy: 0.1405\n",
            "Epoch 29/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -3666478.2500 - accuracy: 0.1405\n",
            "Epoch 30/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -3994071.5000 - accuracy: 0.1405\n",
            "Epoch 31/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -4339085.0000 - accuracy: 0.1405\n",
            "Epoch 32/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: -4701432.5000 - accuracy: 0.1405\n",
            "Epoch 33/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -5082787.5000 - accuracy: 0.1405\n",
            "Epoch 34/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: -5482953.5000 - accuracy: 0.1405\n",
            "Epoch 35/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -5902558.0000 - accuracy: 0.1420\n",
            "Epoch 36/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -6341658.5000 - accuracy: 0.1405\n",
            "Epoch 37/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -6800013.5000 - accuracy: 0.1405\n",
            "Epoch 38/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -7277721.5000 - accuracy: 0.1405\n",
            "Epoch 39/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -7776124.5000 - accuracy: 0.1430\n",
            "Epoch 40/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -8296062.0000 - accuracy: 0.1405\n",
            "Epoch 41/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -8837011.0000 - accuracy: 0.1405\n",
            "Epoch 42/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -9399819.0000 - accuracy: 0.1410\n",
            "Epoch 43/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -9985026.0000 - accuracy: 0.1405\n",
            "Epoch 44/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -10592582.0000 - accuracy: 0.1405\n",
            "Epoch 45/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -11222697.0000 - accuracy: 0.1405\n",
            "Epoch 46/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -11876430.0000 - accuracy: 0.1405\n",
            "Epoch 47/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -12554206.0000 - accuracy: 0.1405\n",
            "Epoch 48/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -13256407.0000 - accuracy: 0.1410\n",
            "Epoch 49/50\n",
            "400/400 [==============================] - 1s 2ms/step - loss: -13982836.0000 - accuracy: 0.1405\n",
            "Epoch 50/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: -14735218.0000 - accuracy: 0.1405\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78c3c3bebd30>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sj-gT7aO0Ki-",
        "outputId": "4075767f-a669-4ae8-a499-c58b8dc6dd71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-45e6213c6e02>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "Mv648QnbcCO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452c4081-5ba0-4f62-d952-8e0d16b0b956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi model: 0.1428571492433548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = \"./my_model.h5\"\n",
        "model.save(saved_model_path)"
      ],
      "metadata": {
        "id": "s7qeSWDZcDab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads the data from the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        data: The loaded data.\n",
        "    \"\"\"\n",
        "\n",
        "    data = pd.read_csv(\"tujuan.csv\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Preprocesses the data.\n",
        "\n",
        "    Args:\n",
        "        data: The data to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "        data: The preprocessed data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert the minat column to numeric.\n",
        "    data[\"minat\"] = pd.get_dummies(data[\"minat\"])\n",
        "\n",
        "    # One-hot encode the tipe_encoded column.\n",
        "    onehot_encoder = OneHotEncoder(sparse=False)\n",
        "    data[\"tipe_encoded\"] = onehot_encoder.fit_transform(data[\"tipe_encoded\"].values.reshape(-1, 1))\n",
        "    data[\"tipe_encoded\"] = pd.DataFrame(data[\"tipe_encoded\"], columns=[\"tipe_\" + str(i) for i in range(data[\"tipe_encoded\"].shape[1])])\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def train_model(data, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Trains the model.\n",
        "\n",
        "    Args:\n",
        "        data: The data used to train the model.\n",
        "        X_train: The training data.\n",
        "        y_train: The training labels.\n",
        "\n",
        "    Returns:\n",
        "        model: The trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the model.\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model.\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model.\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Evaluates the model.\n",
        "\n",
        "    Args:\n",
        "        model: The model to be evaluated.\n",
        "        X_test: The test data.\n",
        "        y_test: The test labels.\n",
        "\n",
        "    Returns:\n",
        "        accuracy: The accuracy of the model.\n",
        "    \"\"\"\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test, y_test)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def fuzzy_recommend(user_data, model, min_score=0.75):\n",
        "    \"\"\"\n",
        "    Mencari rekomendasi fuzzy untuk pengguna berdasarkan data pengguna dan model.\n",
        "\n",
        "    Args:\n",
        "        user_data: Data pengguna yang digunakan untuk mencari rekomendasi.\n",
        "        model: Model prediksi yang telah dilatih.\n",
        "        min_score: Skor minimum rekomendasi yang dianggap signifikan (default 0.75).\n",
        "\n",
        "    Returns:\n",
        "        rekomendasi: List berisi string rekomendasi dengan skornya masing-masing.\n",
        "    \"\"\"\n",
        "\n",
        "    rekomendasi = []\n",
        "\n",
        "    # Preprocess data pengguna\n",
        "    user_data = preprocess_data(user_data)\n",
        "\n",
        "    # Prediksi minat pengguna dengan model\n",
        "    predicted_minat = model.predict(user_data)\n",
        "\n",
        "    # Cari kata kunci minat pengguna dari prediksi\n",
        "    for key, val in predicted_minat.items():\n",
        "        if val > min_score:\n",
        "            key_words = key.split(\"_\")\n",
        "            rekomendasi.append((key, val, fuzz.ratio(key_words[0], \"teknik\")))\n",
        "\n",
        "    # Urutkan rekomendasi berdasarkan skor fuzzy dan skor model\n",
        "    rekomendasi.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "\n",
        "    # Kembalikan list rekomendasi\n",
        "    return rekomendasi\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    The main function.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data.\n",
        "    data = load_data()\n",
        "\n",
        "    # Preprocess the data.\n",
        "    data = preprocess_data(data)\n",
        "\n",
        "    # Split the data into training and testing sets.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data.drop(\"minat\", axis=1), data[\"minat\"], test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model.\n",
        "    model = train_model(data, X_train, y_train)\n",
        "\n",
        "    # Evaluate the model.\n",
        "    accuracy = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    print(\"Accuracy: %.2f\" % (accuracy * 100))\n",
        "\n",
        "    # Get user data.\n",
        "    user_data = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
        "\n",
        "    # Get recommendations.\n",
        "    rekomendasi = fuzzy_recommend(user_data, model)\n",
        "\n",
        "    # Print recommendations.\n",
        "    for key, score, fuzzy_score in rekomendasi:\n",
        "        print(f\"Rekomendasi: {key}, Score: {score:.2f}, Fuzzy Score: {fuzzy_score}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "Ih1rkc8CBbtn",
        "outputId": "bd7443e8-9700-4145-d3b6-06e89b7e73e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4c07f679ed53>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzywuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/mokhaaaa/Dataset/9e7e638b9e79b8d12183cb30da29c18e89fb9078/tujuan_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Pisahkan fitur dan label\n",
        "features = df.iloc[:, :-1]  # Ambil semua kolom kecuali kolom terakhir (Minat)\n",
        "labels = df['minat'].str.strip()\n",
        "\n",
        "# Preprocess data (Normalisasi data jika diperlukan)\n",
        "# Disini kita akan menggunakan Min-Max Scaling sebagai contoh\n",
        "min_max_scaler = MinMaxScaler()\n",
        "features_normalized = min_max_scaler.fit_transform(features)\n",
        "\n",
        "# Pisahkan data menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_normalized, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Buat dan latih model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\", input_shape=(features.shape[1],)),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Latih model dengan data latih\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluasi model pada data uji\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Prediksi dengan data baru (70 jawaban user)\n",
        "new_data = [4,5,4,3,5,4,3,5,4,5,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3]\n",
        "new_data = min_max_scaler.transform([new_data])  # Normalisasi data baru\n",
        "prediction = model.predict(new_data)\n",
        "predicted_interest = tf.keras.backend.argmax(prediction[0])\n",
        "print(f'Predicted Interest: {predicted_interest}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hmp0Yb8Jrei5",
        "outputId": "e5d21e94-930a-4dfe-e3c6-0d916608ea44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0eb0dcc55d9e>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Latih model dengan data latih\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Evaluasi model pada data uji\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node Cast_1 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-6-0eb0dcc55d9e>\", line 33, in <cell line: 33>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1155, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 708, in update_state\n\nCast string to float is not supported\n\t [[{{node Cast_1}}]] [Op:__inference_train_function_962]"
          ]
        }
      ]
    }
  ]
}